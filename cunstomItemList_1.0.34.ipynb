{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(ll), type(ll.train), len(ll.lists)\n",
      "<class 'fastai.data_block.LabelLists'> <class 'fastai.data_block.LabelList'> 2\n",
      "----------------ll.train----------------\n",
      "LabelList\n",
      "y: CategoryList (9000 items)\n",
      "[Category 5, Category 3, Category 5, Category 2, Category 5]...\n",
      "Path: data/yelp_dataset\n",
      "x: MixedTabularList (9000 items)\n",
      "[MixedTabularLine business_id wH4Q0y8C-lkq21yf4WWedw; user_id LAEJWZSvzsfWJ686VOaQig; business_stars 4.0; business_postal_code 85260; business_state AZ; useful 0.1650; user_average_stars 1.5663; user_review_count -0.3320; business_review_count -0.3931; Text:xxbos Although I had heard of xxunk mainly from seeing it xxunk in health conscious friends' xxunk xxunk I had never tried it. This location is rather new and conveniently located to me, so I gave it a try. It's AMAZING! Staff and the customer service they provide are xxunk and the having tried the juices xxunk xxunk to order), smoothies & acai bowls, I'm in love. My 3 year old daughter even enjoyed the Pink Flamingo smoothie (which they sell in kids size for little xxunk They also sell pre-made xxunk and protein drinks in a small xxunk cooler area by the check out, although I haven't tried these yet. And there's a limited selection of granola & protein bars plus some kale chips in terms of snacks. \n",
      "\n",
      "If you're craving a treat, treat the xxunk Berry or PB Bowl which is like sorbet almost and comes topped with fresh berries, banana & granola, making it a perfect breakfast or afternoon snack. Little less filling but equally delicious are the smoothies. Or get refreshed and xxunk with the juices without the hassle of cleaning your xxunk at home xxunk anyone who juices knows it's a pain in xxunk Drinks and bowls run around xxunk ish and there's options to add protein, extra greens, or customize anything. \n",
      "\n",
      "For me, this place has been a great place to stop by with my daughter after preschool and/or a good way to ensure I don't go grocery shopping at Sprouts xxunk parking lot) hungry :), MixedTabularLine business_id cRMC2eQ9CP6ivhEY8EdaGg; user_id TwilnpgwW43r9-O2AS4PDQ; business_stars 3.5; business_postal_code M4Y 2C5; business_state ON; useful -0.0993; user_average_stars -0.7442; user_review_count -0.0778; business_review_count -0.4249; Text:xxbos Last week I met up with a xxunk friend for the first time after xxunk graduation for burritos at Chino xxunk Dos xxunk the Church street venue. I'd never been to this Mexican fast food joint before, but I heard great things about their burritos, which is the only thing they make and serve. I was glad to find a spotless and nicely lit dining area and knowledgeable and friendly burrito xxunk cashiers xxunk the same xxunk menu is rather limited, but that's not necessarily a bad thing because what they offer is actually quite good and there's something for everyone, particularly for me, the xxunk they have 1 vegetarian burrito with cheese and sour cream, but they also have 1 vegan burrito that is sans dairy and meat - \"the juicy xxunk The vegan burrito was so good... priced at $7.99 before taxes, it's actually the most expensive burrito on their menu!!!  The burrito consists of pressed tofu, eggplant, xxunk mushrooms, glass noodles, guacamole, tomatoes, edamame beans, red onions, black beans, green peppers, cilantro, chipotle sauce, rustic xxunk all wrapped in a whole wheat wrap. xxunk have the option between white and whole xxunk The cooks told me that they made their own guacamole at the restaurant, and to me, anything made from scratch is a big bonus! One set back to my burrito experience was the hot sauce... it wasn't hot enough, even though I'd asked for extra hot xxunk LOVE spicy food. \n",
      "\n",
      "You should check this place out if you like Asian food and Mexican food... the xxunk influence on my burrito made it a crazy dining experience for my taste xxunk those Chino xxunk xxunk xxunk Chino xxunk = xxunk xxunk in xxunk, MixedTabularLine business_id 1vLf-v7foAu3tJ7vAEoKdA; user_id l3okl_UjyNdqRKAzYGdWaA; business_stars 5.0; business_postal_code 85254; business_state AZ; useful -0.3635; user_average_stars -0.9803; user_review_count -0.2949; business_review_count -0.2798; Text:xxbos Our xxunk xxunk this place and so do xxunk Wonderful husband and wife team that are true dog lovers. Can't speak highly enough of them.  Only place we really trust to leave our dog. Best advertisement though is that our dog xxunk us to their door after we get out of the car!  :D, MixedTabularLine business_id bWucOPNoIjd8ECdiDyVq9Q; user_id Ck3-SikwEb0U9G7RKh-O_w; business_stars 4.5; business_postal_code 85225; business_state AZ; useful -0.3635; user_average_stars -0.7815; user_review_count -0.3035; business_review_count 0.0014; Text:xxbos It wasn't xxunk we have been going to xxunk for several years and it's only 2 miles away from xxunk xxunk Every time I find a new Chinese place, I am xxunk comparison to xxunk xxunk Panda was the same feeling. Plus, we spent 30% more money for 30% less food than we get at xxunk AND it wasn't nearly as tasty as xxunk, MixedTabularLine business_id tIvDO_1WNbb6UAifErQ-Ug; user_id cwZ64E_XT92XesWkQh85YQ; business_stars 4.0; business_postal_code M5A 3C4; business_state ON; useful -0.3635; user_average_stars 1.3799; user_review_count 0.1336; business_review_count -0.2722; Text:xxbos We were at the Distillery district in Toronto.  The xxunk has one of the most interesting the decor and spaces for a coffee shop.  A xxunk ceiling, funky decor and friendly staff makes for a great place to enjoy the xxunk Flat White I ordered.\n",
      "\n",
      "I would recommend searching out xxunk Coffee shop if you're in Toronto.]...\n",
      "Path: data/yelp_dataset\n",
      "----------------all----------------\n",
      "ll.train.x[0]: business_id wH4Q0y8C-lkq21yf4WWedw; user_id LAEJWZSvzsfWJ686VOaQig; business_stars 4.0; business_postal_code 85260; business_state AZ; useful 0.1650; user_average_stars 1.5663; user_review_count -0.3320; business_review_count -0.3931; Text:xxbos Although I had heard of xxunk mainly from seeing it xxunk in health conscious friends' xxunk xxunk I had never tried it. This location is rather new and conveniently located to me, so I gave it a try. It's AMAZING! Staff and the customer service they provide are xxunk and the having tried the juices xxunk xxunk to order), smoothies & acai bowls, I'm in love. My 3 year old daughter even enjoyed the Pink Flamingo smoothie (which they sell in kids size for little xxunk They also sell pre-made xxunk and protein drinks in a small xxunk cooler area by the check out, although I haven't tried these yet. And there's a limited selection of granola & protein bars plus some kale chips in terms of snacks. \n",
      "\n",
      "If you're craving a treat, treat the xxunk Berry or PB Bowl which is like sorbet almost and comes topped with fresh berries, banana & granola, making it a perfect breakfast or afternoon snack. Little less filling but equally delicious are the smoothies. Or get refreshed and xxunk with the juices without the hassle of cleaning your xxunk at home xxunk anyone who juices knows it's a pain in xxunk Drinks and bowls run around xxunk ish and there's options to add protein, extra greens, or customize anything. \n",
      "\n",
      "For me, this place has been a great place to stop by with my daughter after preschool and/or a good way to ensure I don't go grocery shopping at Sprouts xxunk parking lot) hungry :)\n",
      "ll.train.y[0]: 5\n",
      "ll.train.x.codes[0]: [7170 3012    7  311    2]\n",
      "ll.train.x.cat_names: ['business_id', 'user_id', 'business_stars', 'business_postal_code', 'business_state']\n",
      "ll.train.x.text_ids[0] [    2  1310    11    30 ...   532 13593  1098   624]\n",
      "--------------------Length------------------------\n",
      "17406 17406\n",
      "--------------------databunch------------------------\n",
      "2 3 64 64 64 torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TABULAR:<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>  <col width='10%'>  <col width='10%'>  <col width='10%'>  <col width='10%'>  <col width='10%'>  <col width='10%'>  <col width='10%'>  <col width='10%'>  <col width='10%'>  <col width='10%'>  <tr>\n",
       "    <th>business_id</th>\n",
       "    <th>user_id</th>\n",
       "    <th>business_stars</th>\n",
       "    <th>business_postal_code</th>\n",
       "    <th>business_state</th>\n",
       "    <th>useful</th>\n",
       "    <th>user_average_stars</th>\n",
       "    <th>user_review_count</th>\n",
       "    <th>business_review_count</th>\n",
       "    <th>target</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>hXB72crkUuzBH9CDONTmew</th>\n",
       "    <th>uIsZ7l5YjVVgqK9R3GAddg</th>\n",
       "    <th>3.5</th>\n",
       "    <th>L4H 0P8</th>\n",
       "    <th>ON</th>\n",
       "    <th>-0.3635</th>\n",
       "    <th>1.5663</th>\n",
       "    <th>-0.3434</th>\n",
       "    <th>-0.4542</th>\n",
       "    <th>5</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>rd8NXOBTsASiXriuooki_A</th>\n",
       "    <th>m-_Ed9mCK_jNN1T5sC51aQ</th>\n",
       "    <th>2.5</th>\n",
       "    <th>89118</th>\n",
       "    <th>NV</th>\n",
       "    <th>0.1650</th>\n",
       "    <th>0.0011</th>\n",
       "    <th>-0.2863</th>\n",
       "    <th>-0.3944</th>\n",
       "    <th>5</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>vQq_sX0kSAUdT3yLW06q5A</th>\n",
       "    <th>hDv3EdtJxpa9gCvtXsqw5A</th>\n",
       "    <th>4.0</th>\n",
       "    <th>85251</th>\n",
       "    <th>AZ</th>\n",
       "    <th>-0.3635</th>\n",
       "    <th>-0.9182</th>\n",
       "    <th>-0.2920</th>\n",
       "    <th>0.0052</th>\n",
       "    <th>5</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>wsecg1D5QMY_9soSHmiNsQ</th>\n",
       "    <th>WbsBXaQJ8ff_TxpE65ER-w</th>\n",
       "    <th>5.0</th>\n",
       "    <th>89179</th>\n",
       "    <th>NV</th>\n",
       "    <th>-0.3635</th>\n",
       "    <th>-0.9182</th>\n",
       "    <th>-0.3349</th>\n",
       "    <th>-0.3956</th>\n",
       "    <th>5</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>hRuJImoZk7U4AnIeqZSQmQ</th>\n",
       "    <th>zzOxlK5lm7jlulotNoYd4g</th>\n",
       "    <th>4.5</th>\n",
       "    <th>85295</th>\n",
       "    <th>AZ</th>\n",
       "    <th>-0.3635</th>\n",
       "    <th>0.9452</th>\n",
       "    <th>-0.3349</th>\n",
       "    <th>-0.2391</th>\n",
       "    <th>5</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "TEXT:<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>  <col width='90%'>  <col width='1%'>  <tr>\n",
       "    <th>text_data</th>\n",
       "    <th>target</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos(2) King(2171) xxunk(0) food(42) quality(260) is(16) excellent.(822) The(23) staff(118) is(16) amazing(232) and(9) very(40) friendly.(586) We(53) always(99) enjoy(386) their(52) food.(216) Food(464) is(16) awesome(409) and(9) service(73) is(16) so(36) quick.(2173) Would(854) love(123) to(12) visit(296) again(245) and(9) xxunk(0) you(26) are(35) really(66) looking(191) for(17) a(10) great(59) taste(290) in(18) Indian(1136) food(42) then(135) come(107) visit(296) this(27) place.(215) xxunk(0) is(16) the(8) best(108) host!(17347)</th>\n",
       "    <th>5</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos(2) Amazing(1234) service(73) today(668) guys!(3097) I(11) recommend(146) you(26) order(120) from(50) this(27) xxunk(0) not(31) the(8) one(58) on(25) Blue(2791) xxunk(0) Let(1949) me(41) tell(315) you(26) what(76) happened(1075) today.(1628) I(11) ordered(97) three(378) bread(395) bowels(13862) from(50) the(8) store(303) on(25) Blue(2791) Diamond(8500) around(163) xxunk(0) xxunk(0) came(105) around(163) and(9) still(167) no(87) delivery.(5291) I(11) called(246) and(9) was(13) on(25) hold(1094) for(17) 20(557) minutes(183) and(9) no(87) one(58) answered.(10793) So(195) I(11) called(246) the(8) store(303) on(25) Decatur(8812) and(9) explained(976) what(76) happened(1075) to(12) xxunk(0) He(170) tried(211) to(12) call(317) the(8) store(303) for(17) me(41) as(38) well(151) however(817) they(29) didn't(102) answer(1419) for(17) him(251) either.(1003) While(746) I(11) was(13) on(25) the(8) phone(439) with(21) Jon(7009) from(50) the(8) Decatur(8812) store(303) the(8) delivery(858) driver(1802) from(50) the(8) Blue(2791) Diamond(8500) store(303) shows(1548) up(63) and(9) drops(6442) the(8) bread(395) bowls(2528) all(49) over(116) my(20) front(332) door(577) xxunk(0) He(170) looked(328) at(34) me(41) like(43) he(85) expected(818) me(41) to(12) pick(496) it(19) up(63) and(9) eat(179) it.(127) I(11) told(161) him(251) to(12) take(150) it(19) back(72) and(9) credit(1072) my(20) account.(7010) I(11) now(256) explained(976) this(27) to(12) Jon(7009) from(50) the(8) Decatur(8812) store(303) and(9) he(85) apologized(2133) for(17) that(22) stores(1601) behavior(4887) and(9) sent(923) me(41) three(378) free(321) bread(395) xxunk(0) from(50) his(148) store.(1180) I(11) totally(732) didn't(102) expect(510) that(22) but(24) how(128) amazing(232) is(16) that.(635) Jon(7009) you(26) really(66) made(121) our(46) night(221) and(9) we(33) appreciate(1230) you.(630) You(204) deserve(2714) a(10) raise(6898) for(17) going(130) above(676) and(9) beyond(779) even(89) when(64) your(68) store(303) was(13) not(31) the(8) store(303) that(22) messed(2880) up.(607) You(204) made(121) me(41) feel(193) different(220) about(61) xxunk(0) and(9) I(11) won't(393) let(359) the(8) Blue(2791) Diamond(8500) store(303) alter(9514) my(20) opinion(1699) at(34) all(49) because(79) of(15) you.(630) Thank(584) you!(2507)</th>\n",
       "    <th>5</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos(2) Wow!(4594) Gourmet(8779) food(42) on(25) beer(349) budget(2706) ?(4536) And(201) in(18) xxunk(0) I(11) must(416) be(37) xxunk(0) This(78) is(16) one(58) of(15) those(356) places(309) you(26) almost(334) want(144) to(12) keep(466) secret(3475) for(17) fear(6936) that(22) it(19) will(65) become(1291) too(125) busy.(1454) Love(512) the(8) outdoor(1370) patio(688) too.(457) Recommend(5787) Shrimp(2567) xxunk(0) Short(7093) ribs,(2901) and(9) Guac.(16904) Good(529) pours(13514) on(25) wine,(2892) too!(1079)</th>\n",
       "    <th>5</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos(2) xxunk(0) did(104) a(10) fantastic(763) xxunk(0) Would(854) def(3276) call(317) him(251) again(245) in(18) xxunk(0) can't(203) go(69) wrong(580) hiring(6160) xxunk(0) xxunk(0) Alexander(10493)</th>\n",
       "    <th>5</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos(2) Love(512) this(27) place!(636) Read(7588) about(61) it(19) on(25) Yelp(869) for(17) a(10) while,(3822) finally(460) decided(285) to(12) give(152) it(19) a(10) go(69) last(200) night.(588) Did(2248) not(31) disappoint!(6290) Fabulous(7067) friendly(143) xxunk(0) personal(1107) laid(2455) back(72) service;(15544) clientele(5857) were(32) real(545) xxunk(0) just(44) a(10) young(1122) party(480) crowd.(2630) Happy(2312) hour(299) lasts(8335) until(350) xxunk(0) great(59) xxunk(0) good(48) xxunk(0) delicious(284) grilled(738) cheese(252) xxunk(0) the(8) one(58) with(21) xxunk(0) So(195) glad(675) we(33) stopped(641) xxunk(0) ending(5127) up(63) staying(1073) a(10) couple(322) hours!(9470) Will(690) definitely(119) be(37) back;(15735) I(11) can(77) see(154) this(27) being(184) our(46) go-to(2271) place(39) for(17) xxunk(0) Brilliant(14373) business(383) plan,(15736) great(59) location,(1205) excellent(406) service.(244) Hats(9645) off(136) to(12) you(26) guys!(3097)</th>\n",
       "    <th>5</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Author: Zhangjiekui\n",
    "# Date: 2019-7-7 16:49\n",
    "# torch.set_printoptions(linewidth=300)\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# net=Net()\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#   print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#   # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "#   net = nn.DataParallel(net)\n",
    "# net.to(device)\n",
    "\n",
    "# sys.path.append('utils')  #for import module in utils\n",
    "# from proj_adaptive_softmax import ProjectedAdaptiveLogSoftmax\n",
    "\n",
    "\n",
    "# fastai version: 1.0.34 验证是正确的\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import pdb\n",
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.tabular import *\n",
    "from fastai.text.data import _join_texts\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f'fastai version: {fastai.__version__}')\n",
    "torch.cuda.set_device(1)\n",
    "print(f'using GPU: {torch.cuda.current_device()}')\n",
    "\n",
    "PATH=Path('data/yelp_dataset/')\n",
    "PATH.mkdir(parents=True,exist_ok=True)\n",
    "print(Path.cwd())\n",
    "\n",
    "# sys.path.append('utils')  # for import module in utils\n",
    "\n",
    "torch.set_printoptions(linewidth=300)\n",
    "\n",
    "\n",
    "class MixedTabularLine(TabularLine):  # TabularLine is the sub_class of ItemBase: class TabularLine(ItemBase)\n",
    "    def __init__(self, cat_cols_value_idxs:list, cont_cols_normalized_values, cat_cols_classes:OrderedDict, cat_cont_col_names:OptStrList, txt_idxs, txt_col_names, txt_string):\n",
    "        '''\n",
    "        代表DataFrame中的一行，由三部分组成\n",
    "        <class 'list'>: [tensor([7170, 3012,7,311,2]), tensor([0.1650,1.5663,-0.3320,-0.3931]), array([2,4,545,12, ..., 215,51,792,615])]\n",
    "        list[0]: 类别类型列对应的值\n",
    "        list[1]：数值类型列对应的值\n",
    "        list[2]：文本列对应的文本tokenize、numerize后对应的编码值\n",
    "        :param cat_cols_value_idxs:list(int) ,such as tensor([7170,3012,7,311,2]),then by cat_classes['business_id'][7170] will be the business_id value\n",
    "        :param cont_cols_normalized_values:list(int),such as tensor([ 0.1650,1.5663,-0.3320,-0.3931])\n",
    "        :param cat_cols_classes:OrderedDict;such as OrderedDict('key={cat_cols_name}',array[value={列里所有的类别值}]\n",
    "        :param cat_cont_col_names:list(str)，（类别类型列+数值类型列）列名list\n",
    "        :param txt_idxs:list(int)，文本列对应的文本tokenize、numerize后对应的编码值\n",
    "        :param txt_col_names:数值类型列列名，txt_col_names = ['text']\n",
    "        :param txt_string:文本列中的tokenize处理后的文本值，例如'xxbos xxmaj although i had heard of xxmaj xxunk ,...'\n",
    "        '''\n",
    "\n",
    "        # using TabularLine's :super().__init__\n",
    "        super().__init__(cat_cols_value_idxs, cont_cols_normalized_values, cat_cols_classes, cat_cont_col_names)\n",
    "\n",
    "        # add the text bits\n",
    "        self.txt_idxs=txt_idxs\n",
    "        self.txt_col_names=txt_col_names\n",
    "        self.text=txt_string\n",
    "\n",
    "        # append numericalted text data to your input (represents your X values that are fed into your model)\n",
    "        # self.data = [tensor(cat_cols_value_idxs), tensor(cont_cols_normalized_values), tensor(txt_idxs)]\n",
    "        self.data+=[np.array(self.txt_idxs, dtype=np.int64)]\n",
    "        self.obj=self.data\n",
    "\n",
    "    def __str__(self):\n",
    "        res=super().__str__()+f'Text:{self.text}'\n",
    "        return res\n",
    "\n",
    "class MixedTabularProcessor(TabularProcessor):\n",
    "    tokenizer = Tokenizer(tok_func=BaseTokenizer, lang='en', pre_rules=[], post_rules=[], special_cases=[])\n",
    "\n",
    "    # ItemList or ItemBase? class TabularProcessor(PreProcessor):def __init__(self, ds:ItemBase=None, procs=None):\n",
    "    # todo ItemList or ItemBase? : ds:ItemList（MixedTabularList）\n",
    "\n",
    "    def __init__(self,ds:ItemList=None,procs=None,tokenizer:Tokenizer=tokenizer,chunksize:int=10000,\n",
    "                 vocab:Vocab=None,max_vocab:int=60000,min_freq:int=2):\n",
    "        super().__init__(ds,procs)\n",
    "        self.tokenizer, self.chunksize = ifnone(tokenizer, Tokenizer()), chunksize\n",
    "        vocab=ifnone(vocab,ds.vocab if ds is not None else None)\n",
    "        self.vocab, self.max_vocab, self.min_freq = vocab, max_vocab, min_freq\n",
    "\n",
    "        #   # for testing process_one method\n",
    "        # item = ds.get(0)  # df.Series\n",
    "        # print(type(item))\n",
    "        #\n",
    "        # self.process(ds)\n",
    "        # self.process_one(item)\n",
    "        #\n",
    "        # item1 = ds.get(0)  # df.Series\n",
    "        # print(type(item1))\n",
    "        #\n",
    "        # self.process_one(item1)  #c错误，是供process方法调用的\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        # #     for testing process method\n",
    "        # print(\"self.process(ds) -------------begin\")\n",
    "        # item = ds[0]\n",
    "        # ds.text_cols\n",
    "        #\n",
    "        # print(\"self.process(ds) -------------end\")\n",
    "\n",
    "\n",
    "\n",
    "    # process a single item in a dataset\n",
    "    # todo NOTE: THIS METHOD HAS NOT BEEN TESTED AT THIS POINT (WILL COVER IN A FUTURE ARTICLE)\n",
    "    # process_one(item) 是供process方法调用的:\n",
    "    def process_one(self, item): #item need to be type of df.Series\n",
    "        # process tabular data (copied form tabular.data)\n",
    "        df=pd.DataFrame([item,item])\n",
    "        for proc in self.procs:\n",
    "            proc(df,test=True) #todo\n",
    "        # for proc in self.procs:\n",
    "        #     proc(df, True)\n",
    "        if len(self.cat_names)!=0:\n",
    "            codes=np.stack([c.cat.codes.values for n,c in df[self.cat_names].items()],1).astype(np.int64)+1\n",
    "        else:\n",
    "            codes=[[]]\n",
    "\n",
    "        if len(self.cont_names)!=0:\n",
    "            conts=np.stack([c.astype('float32').values for n,c in df[self.cont_names].items()],1)\n",
    "        else:\n",
    "            conts=[[]]\n",
    "        classes=None\n",
    "        col_names=list(df[self.cat_names].columns.values)+list(df[self.cont_names].columns.values)\n",
    "        # above:  process tabular data (copied form tabular.data)\n",
    "\n",
    "        # below: process textual data (add the customed code lines below)\n",
    "        if len(self.txt_col_names)!=0:\n",
    "            txt=_join_texts(df[self.txt_col_names].values,(len(self.txt_col_names)>1))\n",
    "            txt_toks=self.tokenizer._process_all_1(txt)[0]\n",
    "            txt_ids=np.array(self.vocab.numericalize(txt_toks),dtype=np.int64)\n",
    "        else:\n",
    "            txt_toks,txt_ids=None,[[]]\n",
    "\n",
    "        # return ItemBase\n",
    "        return MixedTabularLine(codes[0],conts[0],classes,col_names,txt_ids,self.txt_col_names,txt_toks)\n",
    "\n",
    "    # processes the entire dataset\n",
    "    def process(self, ds):\n",
    "        # pdb.set_trace()\n",
    "        # process tabular data and then set \"preprocessed=False\" since we still have text data possibly\n",
    "        super().process(ds)\n",
    "        self.txt_col_names=ds.text_cols\n",
    "\n",
    "        ds.preprocessed = False\n",
    "\n",
    "        # process text data from column(s) containing text\n",
    "        if len(ds.text_cols) != 0:\n",
    "            texts = _join_texts(ds.xtra[ds.text_cols].values, (len(ds.text_cols) > 1))\n",
    "\n",
    "            # tokenize (set = .text)\n",
    "            tokens = []\n",
    "            for i in progress_bar(range(0, len(ds), self.chunksize), leave=False):\n",
    "                tokens += self.tokenizer.process_all(texts[i:i + self.chunksize])\n",
    "            ds.text = tokens\n",
    "\n",
    "            # set/build vocab\n",
    "            if self.vocab is None: self.vocab = Vocab.create(ds.text, self.max_vocab, self.min_freq)\n",
    "            ds.vocab = self.vocab\n",
    "            ds.text_ids = [np.array(self.vocab.numericalize(toks), dtype=np.int64) for toks in ds.text]\n",
    "        else:\n",
    "            ds.text, ds.vocab, ds.text_ids = None, None, []\n",
    "\n",
    "        ds.preprocessed = True\n",
    "\n",
    "\n",
    "# each \"ds\" is of type LabelList(Dataset)\n",
    "class MixedTabularDataBunch(DataBunch):\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path: PathOrStr = '.', bs=64,\n",
    "               pad_idx=1, pad_first=True, no_check: bool = False, **kwargs) -> DataBunch:\n",
    "        # only thing we're doing here is setting the collate_fn = to our new \"pad_collate\" method above\n",
    "        collate_fn = partial(mixed_tabular_pad_collate, pad_idx=pad_idx, pad_first=pad_first)\n",
    "\n",
    "        return super().create(train_ds, valid_ds, test_ds, path=path, bs=bs, num_workers=1,\n",
    "                              collate_fn=collate_fn, **kwargs)  #todo , no_check=no_check\n",
    "\n",
    "        # return super().create(train_ds, valid_ds, test_ds, path=path, bs=bs, num_workers=1,\n",
    "        #                       collate_fn=collate_fn, no_check=no_check, **kwargs)\n",
    "\n",
    "\n",
    "# similar to the \"fasta.text.data.pad_collate\" except that it is designed to work with MixedTabularLine items,\n",
    "# where the final thing in an item is the numericalized text ids.\n",
    "# we need a collate function to ensure a square matrix with the text ids, which will be of variable length.\n",
    "def mixed_tabular_pad_collate(samples: BatchSamples,\n",
    "                              pad_idx: int = 1, pad_first: bool = True) -> Tuple[torch.LongTensor, torch.LongTensor]:\n",
    "    \"Function that collect samples and adds padding.\"\n",
    "\n",
    "    samples = to_data(samples)\n",
    "    max_len = max([len(s[0][-1]) for s in samples])\n",
    "    res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "\n",
    "    for i, s in enumerate(samples):\n",
    "        if pad_first:\n",
    "            res[i, -len(s[0][-1]):] = torch.LongTensor(s[0][-1])\n",
    "        else:\n",
    "            res[i, :len(s[0][-1]):] = torch.LongTensor(s[0][-1])\n",
    "\n",
    "        # replace the text_ids array (the last thing in the inputs) with the padded tensor matrix\n",
    "        s[0][-1] = res[i]\n",
    "\n",
    "    # for the inputs, return a list containing 3 elements: a list of cats, a list of conts, and a list of text_ids\n",
    "    return [x for x in zip(*[s[0] for s in samples])], tensor([s[1] for s in samples])\n",
    "\n",
    "\n",
    "class MixedTabularList(TabularList):\n",
    "    \"A custom `ItemList` that merges tabular data along with textual data\"\n",
    "\n",
    "    _item_cls = MixedTabularLine\n",
    "    _processor = MixedTabularProcessor\n",
    "    _bunch = MixedTabularDataBunch\n",
    "\n",
    "    def __init__(self, items: Iterator, cat_names: OptStrList = None, cont_names: OptStrList = None,\n",
    "                 text_cols=None, vocab: Vocab = None, pad_idx: int = 1,\n",
    "                 procs=None, **kwargs) -> 'MixedTabularList':\n",
    "        # pdb.set_trace()\n",
    "        super().__init__(items, cat_names, cont_names, procs, **kwargs)\n",
    "\n",
    "        self.cols = [] if cat_names == None else cat_names.copy()\n",
    "        if cont_names: self.cols += cont_names.copy()\n",
    "        if txt_cols: self.cols += text_cols.copy()\n",
    "\n",
    "        self.text_cols, self.vocab, self.pad_idx = text_cols, vocab, pad_idx\n",
    "\n",
    "        # add any ItemList state into \"copy_new\" that needs to be copied each time \"new()\" is called;\n",
    "        # your ItemList acts as a prototype for training, validation, and/or test ItemList instances that\n",
    "        # are created via ItemList.new()\n",
    "        self.copy_new += ['text_cols', 'vocab', 'pad_idx']\n",
    "\n",
    "        self.preprocessed = False\n",
    "\n",
    "    # defines how to construct an ItemBase from the data in the ItemList.items array\n",
    "    def get(self, i):\n",
    "        if not self.preprocessed:\n",
    "            return self.xtra.iloc[i][self.cols] if hasattr(self, 'xtra') else self.items[i]\n",
    "\n",
    "        codes = [] if self.codes is None else self.codes[i]\n",
    "        conts = [] if self.conts is None else self.conts[i]\n",
    "        text_ids = [] if self.text_ids is None else self.text_ids[i]\n",
    "        text_string = None if self.text_ids is None else self.vocab.textify(self.text_ids[i])\n",
    "\n",
    "        return self._item_cls(codes, conts, self.classes, self.col_names, text_ids, self.text_cols, text_string)\n",
    "\n",
    "    # this is the method that is called in data.show_batch(), learn.predict() or learn.show_results()\n",
    "    # to transform a pytorch tensor back in an ItemBase.\n",
    "    # in a way, it does the opposite of calling ItemBase.data. It should take a tensor t and return\n",
    "    # the same king of thing as the get method.\n",
    "    def reconstruct(self, t: Tensor):\n",
    "        return self._item_cls(t[0], t[1], self.classes, self.col_names,\n",
    "                              t[2], self.text_cols, self.vocab.textify(t[2]))\n",
    "\n",
    "    # tells fastai how to display a custom ItemBase when data.show_batch() is called\n",
    "    def show_xys(self, xs, ys) -> None:\n",
    "        \"Show the `xs` (inputs) and `ys` (targets).\"\n",
    "        from IPython.display import display, HTML\n",
    "\n",
    "        # show tabular\n",
    "        display(HTML('TABULAR:<br>'))\n",
    "        super().show_xys(xs, ys)\n",
    "\n",
    "        # show text\n",
    "        items = [['text_data', 'target']]\n",
    "        for i, (x, y) in enumerate(zip(xs, ys)):\n",
    "            res = []\n",
    "            res += [' '.join([f'{tok}({self.vocab.stoi[tok]})'\n",
    "                              for tok in x.text.split() if (not self.vocab.stoi[tok] == self.pad_idx)])]\n",
    "\n",
    "            res += [str(y)]\n",
    "            items.append(res)\n",
    "\n",
    "        col_widths = [90, 1]\n",
    "\n",
    "        display(HTML('TEXT:<br>'))\n",
    "        display(HTML(text2html_table(items, (col_widths))))\n",
    "\n",
    "    # tells fastai how to display a custom ItemBase when learn.show_results() is called\n",
    "    def show_xyzs(self, xs, ys, zs):\n",
    "        \"Show `xs` (inputs), `ys` (targets) and `zs` (predictions).\"\n",
    "        from IPython.display import display, HTML\n",
    "\n",
    "        # show tabular\n",
    "        super().show_xyzs(xs, ys, zs)\n",
    "\n",
    "        # show text\n",
    "        items = [['text_data', 'target', 'prediction']]\n",
    "        for i, (x, y, z) in enumerate(zip(xs, ys, zs)):\n",
    "            res = []\n",
    "            res += [' '.join([f'{tok}({self.vocab.stoi[tok]})'\n",
    "                              for tok in x.text.split() if (not self.vocab.stoi[tok] == self.pad_idx)])]\n",
    "\n",
    "            res += [str(y), str(z)]\n",
    "            items.append(res)\n",
    "\n",
    "        col_widths = [90, 1, 1]\n",
    "        display(HTML('<br>' + text2html_table(items, (col_widths))))\n",
    "\n",
    "    @classmethod\n",
    "    def from_df(cls, df: DataFrame, cat_names: OptStrList = None, cont_names: OptStrList = None,\n",
    "                text_cols=None, vocab=None, procs=None, xtra:DataFrame=None, **kwargs) -> 'ItemList':\n",
    "\n",
    "        return cls(items=range(len(df)), cat_names=cat_names, cont_names=cont_names,\n",
    "                   text_cols=text_cols, vocab=vocab, procs=procs, xtra=df, **kwargs)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # data = (ImageList.from_folder(path)  # Where to find the data? -> in path and its subfolders\n",
    "    #         .split_by_folder()  # How to split in train/valid? -> use the folders\n",
    "    #         .label_from_folder()  # How to label? -> depending on the folder of the filenames\n",
    "    #         .add_test_folder()  # Optionally add a test set (here default name is test)\n",
    "    #         .transform(tfms, size=64)  # Data augmentation? -> use tfms with a size of 64\n",
    "    #         .databunch())  # Finally? -> use the defaults for conversion to ImageDataBunch\n",
    "\n",
    "    cat_cols = ['business_id', 'user_id', 'business_stars', 'business_postal_code', 'business_state']\n",
    "    cont_cols = ['useful', 'user_average_stars', 'user_review_count', 'business_review_count']\n",
    "    txt_cols = ['text']\n",
    "    dep_var = ['stars']\n",
    "    procs = [FillMissing, Categorify, Normalize]\n",
    "\n",
    "    joined_df = pd.read_csv(PATH / 'joined_sample.csv', index_col=None)\n",
    "    il = MixedTabularList.from_df(joined_df, cat_cols, cont_cols, txt_cols, vocab=None, procs=procs, path=PATH)\n",
    "\n",
    "    print(\"il\"*10)\n",
    "    bil=il.get(0)\n",
    "    print(bil)\n",
    "\n",
    "    ils = il.random_split_by_pct(valid_pct=0.1, seed=42)\n",
    "\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"len(ils.train), len(ils.valid), ils.path\")\n",
    "    print(len(ils.train), len(ils.valid), ils.path)\n",
    "\n",
    "    print(\"-----------------------------------------\")\n",
    "    ll = ils.label_from_df(dep_var)\n",
    "    print(\"type(ll), type(ll.train), len(ll.lists)\")\n",
    "    print(type(ll), type(ll.train), len(ll.lists))\n",
    "\n",
    "    print(\"----------------ll.train\"+\"----------------\")\n",
    "    print(ll.train)\n",
    "\n",
    "    print(\"----------------all\" + \"----------------\")\n",
    "    print(\"ll.train.x[0]:\",ll.train.x[0])\n",
    "\n",
    "    print(\"ll.train.y[0]:\", ll.train.y[0])\n",
    "\n",
    "    print(\"ll.train.x.codes[0]:\",ll.train.x.codes[0])\n",
    "\n",
    "    print(\"ll.train.x.cat_names:\",ll.train.x.cat_names)\n",
    "\n",
    "    print(\"ll.train.x.text_ids[0]\",ll.train.x.text_ids[0])\n",
    "\n",
    "    # print(ll.train.x[0], ll.train.y[0], ll.train.x.codes[0], ll.train.x.cat_names, ll.train.x.text_ids[0])\n",
    "\n",
    "    print(\"--------------------Length------------------------\")\n",
    "\n",
    "    print(len(ll.train.x.vocab.itos), len(ll.valid.x.vocab.itos))\n",
    "\n",
    "    print(\"--------------------databunch------------------------\")\n",
    "    data_bunch = ll.databunch(bs=64)\n",
    "    b = data_bunch.one_batch()\n",
    "    print(len(b), len(b[0]), len(b[0][0]), len(b[0][1]), len(b[0][1]), b[1].shape)\n",
    "    data_bunch.show_batch()\n",
    "\n",
    "\n",
    "    # conts = np.stack([c.astype('float32').values for n, c in joined_df[cont_cols].items()], 1)\n",
    "    #\n",
    "    # codes = np.stack([c.cat.codes.values for n, c in joined_df[cont_cols].items()], 1).astype(np.int64) + 1\n",
    "\n",
    "    # print(len(joined_df))\n",
    "    # print(joined_df.head())\n",
    "    # print(joined_df.describe().T)\n",
    "\n",
    "\n",
    "\n",
    "    # TabularLine(ItemBase): def __init__(self, cats, conts, classes, names)\n",
    "    # MixedTabularLine(TabularLine): def __init__(self, cats, conts, cat_classes, col_names, txt_ids, txt_cols, txt_string):\n",
    "\n",
    "    # cat_cols = ['business_id', 'user_id', 'business_stars', 'business_postal_code', 'business_state']\n",
    "    # cont_cols = ['useful', 'user_average_stars', 'user_review_count', 'business_review_count']\n",
    "    # txt_ids=[0,1,2,3]\n",
    "    # txt_string=['0s','1s','2s','3s']\n",
    "    # txt_cols = ['text']\n",
    "    # col_names=cat_cols+cont_cols+txt_cols\n",
    "    # dep_var = ['stars']\n",
    "    # mtl=MixedTabularLine(cat_cols,cont_cols,None,col_names,txt_ids,txt_cols,txt_string)\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
