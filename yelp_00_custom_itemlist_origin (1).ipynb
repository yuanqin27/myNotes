{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yelp-00-custom-itemlist_origin.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T19iE87koYvH",
        "colab_type": "text"
      },
      "source": [
        "# Finding Data Block Nirvana (a journey through the fastai data block API)\n",
        "\n",
        "This notebook illustrates how to create a custom `ItemList` for use in the fastai data block API.  It is heavily annotated to further aid in also understanding how all the different bits in the API interact as well as what is happening at each step and why.\n",
        "\n",
        "Please consult the [fastai docs](https://docs.fast.ai/) for installing required packages and setting up your environment to run the code below.\n",
        "\n",
        "The accompanying Medium article highlighing the data block API mechanics based on my work here can be found [here](https://medium.com/@wgilliam/finding-data-block-nirvana-a-journey-through-the-fastai-data-block-api-c38210537fe4)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gunRG0jnoeoU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ba7b6dd-40ab-4ae0-8485-18ba64c01890"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMM52OAQoYvI",
        "colab_type": "text"
      },
      "source": [
        "## Yelp Dataset\n",
        "\n",
        "This example utilize a subset of the Yelp review dataset I've made available as part of the code repo for the purposes of illustrating how my `MixedTabularList` would work with a pandas DataFrame containing categorical, continuous, and numercalized text data.  The full dataset and documentation can be found following the links below.\n",
        "\n",
        "Available from https://www.yelp.com/dataset/download  \n",
        "Documentation here:  https://www.yelp.com/dataset/documentation/main  \n",
        "More information here:  https://www.yelp.com/dataset\n",
        "\n",
        "Unzip the `joined_sample.zip` .csv file into a `data/yelp_dataset` folder relative to this notebook and you should be good to go."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbJgWkUloYvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLMnIA_5oYvM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2dd41122-2f4f-4cb3-ebf5-e6c0073c2e16"
      },
      "source": [
        "import pdb\n",
        "\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.tabular import *\n",
        "from fastai.text.data import _join_texts\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "# import pysnooper\n",
        "\n",
        "print(f'fastai version: {__version__}')  #=> I test this against 1.0.39"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fastai version: 1.0.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4I8wIpyoYvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.cuda.set_device(1)\n",
        "# print(f'using GPU: {torch.cuda.current_device()}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVLUYGfwoYvU",
        "colab_type": "text"
      },
      "source": [
        "## Configuration and utility methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BjkJQ1WoYvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a6b9c3b-535e-409e-db33-27dd7f000d7f"
      },
      "source": [
        "PATH=Path('/content/drive/My Drive/datafolder/YelpDataset/')\n",
        "FILE=\"joined_sample.csv\"\n",
        "PATH_FILE=PATH/FILE\n",
        "PATH.ls()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/drive/My Drive/datafolder/YelpDataset/joined_sample.csv')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5EDjoSZoYvX",
        "colab_type": "text"
      },
      "source": [
        "## Define ItemBase subclass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrTk-sjHoYvX",
        "colab_type": "text"
      },
      "source": [
        "`ItemBase` defines the inputs for your custom dataset, the X and optionally y values you are going to feed into the `forward` function of your pytorch model.  Here we define what an an input item looks like (we'll let fastai infer the `ItemBase` type to use based on our target values).\n",
        "\n",
        "If your custom `ItemBase` needs to have some kind of data augmentation applied to it, you should overload the `apply_tfms` method as needed.  This method will be called you apply a `transform` block via the Data Block API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZv9s3kUoYvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MixedTabularLine(TabularLine):\n",
        "    \"Item's that include both tabular data(`conts` and `cats`) and textual data (numericalized `ids`)\"\n",
        "    \n",
        "    def __init__(self, cats, conts, cat_classes, col_names, txt_ids, txt_cols, txt_string):\n",
        "        # tabular\n",
        "        super().__init__(cats, conts, cat_classes, col_names)\n",
        "\n",
        "        # add the text bits\n",
        "        self.text_ids = txt_ids\n",
        "        self.text_cols = txt_cols\n",
        "        self.text = txt_string\n",
        "        \n",
        "        # append numericalted text data to your input (represents your X values that are fed into your model)\n",
        "        # self.data = [tensor(cats), tensor(conts), tensor(txt_ids)]\n",
        "        self.data += [ np.array(txt_ids, dtype=np.int64) ]\n",
        "        self.obj = self.data\n",
        "        \n",
        "    def __str__(self):\n",
        "        res = super().__str__() + f'Text: {self.text}'\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDZte2KGoYvb",
        "colab_type": "text"
      },
      "source": [
        "## Define custom Processor, DataBunch, and utility methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN9XYnogoYvc",
        "colab_type": "text"
      },
      "source": [
        "Our custom `ItemList` is going to require a custom `PreProcessor` and a custom `DataBunch`, so we define them here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47Lj5uIOoYvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MixedTabularProcessor(TabularProcessor):\n",
        "    \n",
        "    def __init__(self, ds:ItemList=None, procs=None, \n",
        "                 tokenizer:Tokenizer=None, chunksize:int=10000,\n",
        "                 vocab:Vocab=None, max_vocab:int=60000, min_freq:int=2):\n",
        "        #pdb.set_trace()\n",
        "        super().__init__(ds, procs)\n",
        "    \n",
        "        self.tokenizer, self.chunksize = ifnone(tokenizer, Tokenizer()), chunksize\n",
        "        \n",
        "        vocab = ifnone(vocab, ds.vocab if ds is not None else None)\n",
        "        self.vocab, self.max_vocab, self.min_freq = vocab, max_vocab, min_freq\n",
        "        \n",
        "    # process a single item in a dataset\n",
        "    # NOTE: THIS IS METHOD HAS NOT BEEN TESTED AT THIS POINT (WILL COVER IN A FUTURE ARTICLE)\n",
        "    def process_one(self, item):\n",
        "        # process tabular data (copied form tabular.data)\n",
        "        df = pd.DataFrame([item, item])\n",
        "        for proc in self.procs: proc(df, test=True)\n",
        "            \n",
        "        if len(self.cat_names) != 0:\n",
        "            codes = np.stack([c.cat.codes.values for n,c in df[self.cat_names].items()], 1).astype(np.int64) + 1\n",
        "        else: \n",
        "            codes = [[]]\n",
        "            \n",
        "        if len(self.cont_names) != 0:\n",
        "            conts = np.stack([c.astype('float32').values for n,c in df[self.cont_names].items()], 1)\n",
        "        else: \n",
        "            conts = [[]]\n",
        "            \n",
        "        classes = None\n",
        "        col_names = list(df[self.cat_names].columns.values) + list(df[self.cont_names].columns.values)\n",
        "        \n",
        "        # process textual data\n",
        "        if len(self.text_cols) != 0:\n",
        "            txt = _join_texts(df[self.text_cols].values, (len(self.text_cols) > 1))\n",
        "            txt_toks = self.tokenizer._process_all_1(txt)[0]\n",
        "            text_ids = np.array(self.vocab.numericalize(txt_toks), dtype=np.int64)\n",
        "        else:\n",
        "            txt_toks, text_ids = None, [[]]\n",
        "            \n",
        "        # return ItemBase\n",
        "        return MixedTabularLine(codes[0], conts[0], classes, col_names, text_ids, self.txt_cols, txt_toks)\n",
        "    \n",
        "    # processes the entire dataset\n",
        "    def process(self, ds):\n",
        "        #pdb.set_trace()\n",
        "        # process tabular data and then set \"preprocessed=False\" since we still have text data possibly\n",
        "        super().process(ds)\n",
        "        ds.preprocessed = False\n",
        "        \n",
        "        # process text data from column(s) containing text\n",
        "        if len(ds.text_cols) != 0:\n",
        "            texts = _join_texts(ds.inner_df[ds.text_cols].values, (len(ds.text_cols) > 1))\n",
        "\n",
        "            # tokenize (set = .text)\n",
        "            tokens = []\n",
        "            for i in progress_bar(range(0, len(ds), self.chunksize), leave=False):\n",
        "                tokens += self.tokenizer.process_all(texts[i:i+self.chunksize])\n",
        "            ds.text = tokens\n",
        "\n",
        "            # set/build vocab\n",
        "            if self.vocab is None: self.vocab = Vocab.create(ds.text, self.max_vocab, self.min_freq)\n",
        "            ds.vocab = self.vocab\n",
        "            ds.text_ids = [ np.array(self.vocab.numericalize(toks), dtype=np.int64) for toks in ds.text ]\n",
        "        else:\n",
        "            ds.text, ds.vocab, ds.text_ids = None, None, []\n",
        "            \n",
        "        ds.preprocessed = True\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYThpa_ToYvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# similar to the \"fasta.text.data.pad_collate\" except that it is designed to work with MixedTabularLine items,\n",
        "# where the final thing in an item is the numericalized text ids.\n",
        "# we need a collate function to ensure a square matrix with the text ids, which will be of variable length.\n",
        "def mixed_tabular_pad_collate(samples:BatchSamples, \n",
        "                              pad_idx:int=1, pad_first:bool=True) -> Tuple[LongTensor, LongTensor]:\n",
        "    \"Function that collect samples and adds padding.\"\n",
        "\n",
        "    samples = to_data(samples)\n",
        "    max_len = max([len(s[0][-1]) for s in samples])\n",
        "    res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
        "   \n",
        "    for i,s in enumerate(samples):\n",
        "        if pad_first: \n",
        "            res[i,-len(s[0][-1]):] = LongTensor(s[0][-1])\n",
        "        else:         \n",
        "            res[i,:len(s[0][-1]):] = LongTensor(s[0][-1])\n",
        "            \n",
        "        # replace the text_ids array (the last thing in the inputs) with the padded tensor matrix\n",
        "        s[0][-1] = res[i]\n",
        "              \n",
        "    # for the inputs, return a list containing 3 elements: a list of cats, a list of conts, and a list of text_ids\n",
        "    return [x for x in zip(*[s[0] for s in samples])], tensor([s[1] for s in samples])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uX36dVyoYvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# each \"ds\" is of type LabelList(Dataset)\n",
        "class MixedTabularDataBunch(DataBunch):\n",
        "    @classmethod\n",
        "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs=64, \n",
        "               pad_idx=1, pad_first=True, no_check:bool=False, **kwargs) -> DataBunch:\n",
        "        \n",
        "        # only thing we're doing here is setting the collate_fn = to our new \"pad_collate\" method above\n",
        "        collate_fn = partial(mixed_tabular_pad_collate, pad_idx=pad_idx, pad_first=pad_first)\n",
        "        \n",
        "        return super().create(train_ds, valid_ds, test_ds, path=path, bs=bs,\n",
        "                               collate_fn = collate_fn,  **kwargs) #no_check=no_check,"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOqSzLQNoYvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF4LqNWqoYvn",
        "colab_type": "text"
      },
      "source": [
        "## Define ItemList subclass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8krHe0o5oYvo",
        "colab_type": "text"
      },
      "source": [
        "An `ItemList` consists of a set of `ItemBase` objects. Once created, you can use any of splitting or labeling methods prior to creating a `DataBunch` for training.\n",
        "\n",
        "You'll likely want to set the following three class variables to something specific to your situation:\n",
        "\n",
        "**`_bunch`**:  \n",
        "The name of the class used to create a `DataBunch`.  `TabularList` uses the default `DataBunch` as is and so does not set this variable. We create a custom `DataBunch` here because we need to add padding to the column with the text ids in order to ensure a square matrix per batch before integrating the text bits with the tabular.\n",
        "\n",
        "When you call `databunch()` via the Data Block API, `_bunch.create` will be called passing in the datasets (training, validation and optionally test) defined by your `ItemLists` and returning a set of `DataLoader`s in a `DataBunch` for training.\n",
        "\n",
        "**`_processor`**:  \n",
        "A class or list of classes of type `PreProcessor` that will be used to create the default processor for this `ItemList`.\n",
        "\n",
        "The processors are **called at the end of the labelling** to apply some kind of function on your items. The **default processor of the inputs** can be overriden by passing a `processor` in the kwargs when creating the `ItemList`, the **default processor of the targets** can be overriden by passing a `processor` in the kwargs of the labelling function.\n",
        "\n",
        "Processors are useful for pre-processing data, and **you also need to save any computed state required for future datasets when `data.export()` is called.**\n",
        "\n",
        "**`_item_cls`**:   \n",
        "The name of the class that will be used to create the \"items\" by default.\n",
        "\n",
        "**`_label_cls`**:   \n",
        "The name of the class that will be used to create the labels by default. (**If this variable is set to None, the label class will be guessed** between `CategoryList`, `MultiCategoryList` and `FloatList` depending on the type of the first item. Since we are creating a custom `ItemList` with a very distinct signature, we want to set it to that class)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C2mAL2LoYvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MixedTabularList(TabularList):\n",
        "    \"A custom `ItemList` that merges tabular data along with textual data\"\n",
        "    \n",
        "    _item_cls = MixedTabularLine\n",
        "    _processor = MixedTabularProcessor\n",
        "    _bunch = MixedTabularDataBunch\n",
        "    \n",
        "    def __init__(self, items:Iterator, cat_names:OptStrList=None, cont_names:OptStrList=None, \n",
        "                 text_cols=None, vocab:Vocab=None, pad_idx:int=1, \n",
        "                 procs=None, **kwargs) -> 'MixedTabularList':\n",
        "        #pdb.set_trace()\n",
        "        super().__init__(items, cat_names, cont_names, procs, **kwargs)\n",
        "        \n",
        "        self.cols = [] if cat_names == None else cat_names.copy()\n",
        "        if cont_names: self.cols += cont_names.copy()\n",
        "        if txt_cols: self.cols += text_cols.copy()\n",
        "        \n",
        "        self.text_cols, self.vocab, self.pad_idx = text_cols, vocab, pad_idx\n",
        "        \n",
        "        # add any ItemList state into \"copy_new\" that needs to be copied each time \"new()\" is called; \n",
        "        # your ItemList acts as a prototype for training, validation, and/or test ItemList instances that\n",
        "        # are created via ItemList.new()\n",
        "        self.copy_new += ['text_cols', 'vocab', 'pad_idx']\n",
        "        \n",
        "        self.preprocessed = False\n",
        "        \n",
        "    # defines how to construct an ItemBase from the data in the ItemList.items array\n",
        "    def get(self, i):\n",
        "        if not self.preprocessed: \n",
        "            return self.inner_df.iloc[i][self.cols] if hasattr(self, 'inner_df') else self.items[i]\n",
        "        \n",
        "        codes = [] if self.codes is None else self.codes[i]\n",
        "        conts = [] if self.conts is None else self.conts[i]\n",
        "        text_ids = [] if self.text_ids is None else self.text_ids[i]\n",
        "        text_string = None if self.text_ids is None else self.vocab.textify(self.text_ids[i])\n",
        "        \n",
        "        return self._item_cls(codes, conts, self.classes, self.col_names, text_ids, self.text_cols, text_string)\n",
        "    \n",
        "    # this is the method that is called in data.show_batch(), learn.predict() or learn.show_results() \n",
        "    # to transform a pytorch tensor back in an ItemBase. \n",
        "    # in a way, it does the opposite of calling ItemBase.data. It should take a tensor t and return \n",
        "    # the same king of thing as the get method.\n",
        "    def reconstruct(self, t:Tensor):\n",
        "        return self._item_cls(t[0], t[1], self.classes, self.col_names, \n",
        "                              t[2], self.text_cols, self.vocab.textify(t[2]))\n",
        "    \n",
        "    # tells fastai how to display a custom ItemBase when data.show_batch() is called\n",
        "    def show_xys(self, xs, ys) -> None:\n",
        "        \"Show the `xs` (inputs) and `ys` (targets).\"\n",
        "        from IPython.display import display, HTML\n",
        "        \n",
        "        # show tabular\n",
        "        display(HTML('TABULAR:<br>'))\n",
        "        super().show_xys(xs, ys)\n",
        "        \n",
        "        # show text\n",
        "        items = [['text_data', 'target']]\n",
        "        for i, (x,y) in enumerate(zip(xs,ys)):\n",
        "            res = []\n",
        "            res += [' '.join([ f'{tok}({self.vocab.stoi[tok]})' \n",
        "                              for tok in x.text.split() if (not self.vocab.stoi[tok] == self.pad_idx) ])]\n",
        "                \n",
        "            res += [str(y)]\n",
        "            items.append(res)\n",
        "            \n",
        "        col_widths = [90, 1]\n",
        "        \n",
        "        display(HTML('TEXT:<br>'))\n",
        "        display(HTML(text2html_table(items, (col_widths))))\n",
        "        \n",
        "    # tells fastai how to display a custom ItemBase when learn.show_results() is called\n",
        "    def show_xyzs(self, xs, ys, zs):\n",
        "        \"Show `xs` (inputs), `ys` (targets) and `zs` (predictions).\"\n",
        "        from IPython.display import display, HTML\n",
        "        \n",
        "        # show tabular\n",
        "        super().show_xyzs(xs, ys, zs)\n",
        "        \n",
        "        # show text\n",
        "        items = [['text_data','target', 'prediction']]\n",
        "        for i, (x,y,z) in enumerate(zip(xs,ys,zs)):\n",
        "            res = []\n",
        "            res += [' '.join([ f'{tok}({self.vocab.stoi[tok]})'\n",
        "                              for tok in x.text.split() if (not self.vocab.stoi[tok] == self.pad_idx) ])]\n",
        "                \n",
        "            res += [str(y),str(z)]\n",
        "            items.append(res)\n",
        "            \n",
        "        col_widths = [90, 1, 1]\n",
        "        display(HTML('<br>' + text2html_table(items, (col_widths))))\n",
        "    \n",
        "        \n",
        "    @classmethod\n",
        "    def from_df(cls, df:DataFrame, cat_names:OptStrList=None, cont_names:OptStrList=None, \n",
        "                text_cols=None, vocab=None, procs=None, **kwargs) -> 'ItemList':\n",
        "        \n",
        "        return cls(items=range(len(df)), cat_names=cat_names, cont_names=cont_names, \n",
        "                   text_cols=text_cols, vocab=vocab, procs=procs,inner_df=df.copy(), **kwargs)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3211mUmuoYvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKM7BiIEoYvr",
        "colab_type": "text"
      },
      "source": [
        "## Fetch joined yelp reviews (includes busines and user info)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHYDaLJOoYvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8240bb7-bc89-447b-932e-af6b10b6b9fc"
      },
      "source": [
        "joined_df = pd.read_csv(PATH/'joined_sample.csv', index_col=None)\n",
        "\n",
        "display(len(joined_df))\n",
        "display(joined_df.head())\n",
        "display(joined_df.describe().T)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10197"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>date</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>user_id</th>\n",
              "      <th>user_average_stars</th>\n",
              "      <th>user_compliment_cool</th>\n",
              "      <th>user_compliment_cute</th>\n",
              "      <th>user_compliment_funny</th>\n",
              "      <th>user_compliment_hot</th>\n",
              "      <th>user_compliment_list</th>\n",
              "      <th>user_compliment_more</th>\n",
              "      <th>user_compliment_note</th>\n",
              "      <th>user_compliment_photos</th>\n",
              "      <th>user_compliment_plain</th>\n",
              "      <th>user_compliment_profile</th>\n",
              "      <th>user_compliment_writer</th>\n",
              "      <th>user_cool</th>\n",
              "      <th>user_elite</th>\n",
              "      <th>user_fans</th>\n",
              "      <th>user_friends</th>\n",
              "      <th>user_funny</th>\n",
              "      <th>user_name</th>\n",
              "      <th>user_review_count</th>\n",
              "      <th>user_useful</th>\n",
              "      <th>user_yelping_since</th>\n",
              "      <th>business_address</th>\n",
              "      <th>business_attributes</th>\n",
              "      <th>business_categories</th>\n",
              "      <th>business_city</th>\n",
              "      <th>business_hours</th>\n",
              "      <th>business_is_open</th>\n",
              "      <th>business_latitude</th>\n",
              "      <th>business_longitude</th>\n",
              "      <th>business_name</th>\n",
              "      <th>business_neighborhood</th>\n",
              "      <th>business_postal_code</th>\n",
              "      <th>business_review_count</th>\n",
              "      <th>business_stars</th>\n",
              "      <th>business_state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8jpIK1WHmzzbXPaK51GenQ</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-08-08</td>\n",
              "      <td>3</td>\n",
              "      <td>W7wcVRiw5T8TMrmGnxPsxQ</td>\n",
              "      <td>4</td>\n",
              "      <td>I've been here at least 10 times ... I like it...</td>\n",
              "      <td>1</td>\n",
              "      <td>g6gTSnUKZIxLZPQVrFKscw</td>\n",
              "      <td>4.14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>sJEgIk45pmVEJAHQMDKi4A, xduGhZ92kLqvTGZ2-zX0hg...</td>\n",
              "      <td>0</td>\n",
              "      <td>Debbie</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-10-25</td>\n",
              "      <td>4050 W Ray Rd</td>\n",
              "      <td>{'Alcohol': 'none', 'Ambience': \"{'romantic': ...</td>\n",
              "      <td>American (Traditional), Breakfast &amp; Brunch, Sa...</td>\n",
              "      <td>Chandler</td>\n",
              "      <td>{'Tuesday': '6:30-14:30', 'Wednesday': '6:30-1...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.3209944067</td>\n",
              "      <td>-111.912682</td>\n",
              "      <td>Dessie's Cafe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>85226</td>\n",
              "      <td>67.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>AZ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wH4Q0y8C-lkq21yf4WWedw</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-01-31</td>\n",
              "      <td>0</td>\n",
              "      <td>emypFL3PJjQBcllPZw_d5A</td>\n",
              "      <td>5</td>\n",
              "      <td>Although I had heard of Nekter, mainly from se...</td>\n",
              "      <td>2</td>\n",
              "      <td>LAEJWZSvzsfWJ686VOaQig</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "      <td>EFFWziYSge9vgL5QOuVodA, urMngjIG5D8Xde67j3AqSg...</td>\n",
              "      <td>1</td>\n",
              "      <td>Andrea</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2013-12-24</td>\n",
              "      <td>9301 E Shea Blvd</td>\n",
              "      <td>{'Alcohol': 'none', 'Ambience': \"{'romantic': ...</td>\n",
              "      <td>Juice Bars &amp; Smoothies, Gluten-Free, Food, Ice...</td>\n",
              "      <td>Scottsdale</td>\n",
              "      <td>{'Monday': '6:30-20:0', 'Tuesday': '6:30-20:0'...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>33.5804744425</td>\n",
              "      <td>-111.881062</td>\n",
              "      <td>Nekter Juice Bar</td>\n",
              "      <td>NaN</td>\n",
              "      <td>85260</td>\n",
              "      <td>59.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>AZ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cRMC2eQ9CP6ivhEY8EdaGg</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-09-13</td>\n",
              "      <td>0</td>\n",
              "      <td>5X5ISEAp6HFTpMd_wlq_9w</td>\n",
              "      <td>3</td>\n",
              "      <td>Last week I met up with a highschool friend fo...</td>\n",
              "      <td>1</td>\n",
              "      <td>TwilnpgwW43r9-O2AS4PDQ</td>\n",
              "      <td>3.14</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>2011, 2010, 2012</td>\n",
              "      <td>12</td>\n",
              "      <td>TkzLgJrW-OqwJ4Ws5oYBZg, CxDOIDnH8gp9KXzpBHJYXw...</td>\n",
              "      <td>3</td>\n",
              "      <td>Marie</td>\n",
              "      <td>94</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-25</td>\n",
              "      <td>459 Church Street, 2nd Floor</td>\n",
              "      <td>{'Alcohol': 'none', 'Ambience': \"{'romantic': ...</td>\n",
              "      <td>Mexican, Restaurants, Asian Fusion</td>\n",
              "      <td>Toronto</td>\n",
              "      <td>{'Monday': '12:0-21:0', 'Tuesday': '12:0-21:0'...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.6641927</td>\n",
              "      <td>-79.380196</td>\n",
              "      <td>Chino Locos</td>\n",
              "      <td>Church-Wellesley Village</td>\n",
              "      <td>M4Y 2C5</td>\n",
              "      <td>34.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>ON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>zunMkZ4U2eVojempQtLngg</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-03-07</td>\n",
              "      <td>0</td>\n",
              "      <td>OGekU1U_wWgV--zL2gEgYw</td>\n",
              "      <td>4</td>\n",
              "      <td>A friend and I were driving by and decided to ...</td>\n",
              "      <td>1</td>\n",
              "      <td>eITkQlKYsYqOBASP-QS0iQ</td>\n",
              "      <td>3.72</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>9RBRKzif1GD03M0bIX2hMQ, PHL0ESwylh6SKdmRsMXF0g...</td>\n",
              "      <td>4</td>\n",
              "      <td>Sean</td>\n",
              "      <td>69</td>\n",
              "      <td>10</td>\n",
              "      <td>2007-12-03</td>\n",
              "      <td>5830 W Bell Rd</td>\n",
              "      <td>{'Alcohol': 'full_bar', 'Ambience': \"{'romanti...</td>\n",
              "      <td>Sports Bars, Burgers, Nightlife, Bars, Austral...</td>\n",
              "      <td>Glendale</td>\n",
              "      <td>{'Monday': '11:0-1:0', 'Tuesday': '11:0-1:0', ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.639157700000005</td>\n",
              "      <td>-112.185110</td>\n",
              "      <td>The Australian AZ</td>\n",
              "      <td>NaN</td>\n",
              "      <td>85308</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>AZ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1vLf-v7foAu3tJ7vAEoKdA</td>\n",
              "      <td>0</td>\n",
              "      <td>2014-11-26</td>\n",
              "      <td>1</td>\n",
              "      <td>tTe2cLFmpkLop3wKcT0Zgw</td>\n",
              "      <td>5</td>\n",
              "      <td>Our Bulldog LOVES this place and so do we! Won...</td>\n",
              "      <td>0</td>\n",
              "      <td>l3okl_UjyNdqRKAzYGdWaA</td>\n",
              "      <td>2.95</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>g0arZP7975-VYy6Vff0unQ</td>\n",
              "      <td>1</td>\n",
              "      <td>Jim</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-04-27</td>\n",
              "      <td>7000 E Shea Blvd, Ste 1360</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pets, Pet Services, Pet Groomers, Pet Sitting</td>\n",
              "      <td>Scottsdale</td>\n",
              "      <td>{'Monday': '7:30-19:0', 'Tuesday': '7:30-19:0'...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>33.5828480159</td>\n",
              "      <td>-111.929296</td>\n",
              "      <td>Lori's Grooming</td>\n",
              "      <td>NaN</td>\n",
              "      <td>85254</td>\n",
              "      <td>148.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>AZ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              business_id  cool  ... business_stars  business_state\n",
              "0  8jpIK1WHmzzbXPaK51GenQ     1  ...            3.5              AZ\n",
              "1  wH4Q0y8C-lkq21yf4WWedw     0  ...            4.0              AZ\n",
              "2  cRMC2eQ9CP6ivhEY8EdaGg     1  ...            3.5              ON\n",
              "3  zunMkZ4U2eVojempQtLngg     1  ...            2.5              AZ\n",
              "4  1vLf-v7foAu3tJ7vAEoKdA     0  ...            5.0              AZ\n",
              "\n",
              "[5 rows x 44 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cool</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>0.558498</td>\n",
              "      <td>1.966729</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>70.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>funny</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>0.533588</td>\n",
              "      <td>4.265255</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>388.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stars</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>3.720408</td>\n",
              "      <td>1.455697</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>useful</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>1.369717</td>\n",
              "      <td>3.659338</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>212.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_average_stars</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>3.737775</td>\n",
              "      <td>0.802627</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.390000</td>\n",
              "      <td>3.810000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_compliment_cool</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>37.397078</td>\n",
              "      <td>305.916092</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>13014.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_compliment_cute</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>1.680200</td>\n",
              "      <td>30.828081</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2250.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_compliment_funny</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>37.397078</td>\n",
              "      <td>305.916092</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>13014.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_compliment_hot</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>25.131902</td>\n",
              "      <td>237.917800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9259.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_compliment_list</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>1.210454</td>\n",
              "      <td>27.541980</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2259.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_compliment_more</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>3.204962</td>\n",
              "      <td>42.442618</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3574.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_compliment_note</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>17.022163</td>\n",
              "      <td>120.312999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4899.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_compliment_photos</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>14.491811</td>\n",
              "      <td>187.899869</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10820.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_compliment_plain</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>42.971854</td>\n",
              "      <td>349.577472</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>11741.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_compliment_profile</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>2.659998</td>\n",
              "      <td>64.749984</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5659.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_compliment_writer</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>14.009905</td>\n",
              "      <td>116.461353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5668.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_cool</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>227.449054</td>\n",
              "      <td>2216.091706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>86136.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_fans</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>11.800628</td>\n",
              "      <td>53.306555</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1394.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_useful</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>295.995489</td>\n",
              "      <td>2461.788438</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>91508.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>business_is_open</th>\n",
              "      <td>10197.0</td>\n",
              "      <td>0.870158</td>\n",
              "      <td>0.337892</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>business_longitude</th>\n",
              "      <td>10196.0</td>\n",
              "      <td>-102.759779</td>\n",
              "      <td>16.123493</td>\n",
              "      <td>-122.822578</td>\n",
              "      <td>-115.154257</td>\n",
              "      <td>-111.979535</td>\n",
              "      <td>-81.077144</td>\n",
              "      <td>112.092039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>business_review_count</th>\n",
              "      <td>10196.0</td>\n",
              "      <td>368.311299</td>\n",
              "      <td>783.207371</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>7968.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>business_stars</th>\n",
              "      <td>10196.0</td>\n",
              "      <td>3.736220</td>\n",
              "      <td>0.753075</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           count        mean  ...         75%           max\n",
              "cool                     10197.0    0.558498  ...    0.000000     70.000000\n",
              "funny                    10197.0    0.533588  ...    0.000000    388.000000\n",
              "stars                    10197.0    3.720408  ...    5.000000      5.000000\n",
              "useful                   10197.0    1.369717  ...    2.000000    212.000000\n",
              "user_average_stars       10197.0    3.737775  ...    4.200000      5.000000\n",
              "user_compliment_cool     10197.0   37.397078  ...    2.000000  13014.000000\n",
              "user_compliment_cute     10197.0    1.680200  ...    0.000000   2250.000000\n",
              "user_compliment_funny    10197.0   37.397078  ...    2.000000  13014.000000\n",
              "user_compliment_hot      10197.0   25.131902  ...    1.000000   9259.000000\n",
              "user_compliment_list     10197.0    1.210454  ...    0.000000   2259.000000\n",
              "user_compliment_more     10197.0    3.204962  ...    1.000000   3574.000000\n",
              "user_compliment_note     10197.0   17.022163  ...    2.000000   4899.000000\n",
              "user_compliment_photos   10197.0   14.491811  ...    0.000000  10820.000000\n",
              "user_compliment_plain    10197.0   42.971854  ...    3.000000  11741.000000\n",
              "user_compliment_profile  10197.0    2.659998  ...    0.000000   5659.000000\n",
              "user_compliment_writer   10197.0   14.009905  ...    2.000000   5668.000000\n",
              "user_cool                10197.0  227.449054  ...    5.000000  86136.000000\n",
              "user_fans                10197.0   11.800628  ...    4.000000   1394.000000\n",
              "user_useful              10197.0  295.995489  ...   27.000000  91508.000000\n",
              "business_is_open         10197.0    0.870158  ...    1.000000      4.000000\n",
              "business_longitude       10196.0 -102.759779  ...  -81.077144    112.092039\n",
              "business_review_count    10196.0  368.311299  ...  340.000000   7968.000000\n",
              "business_stars           10196.0    3.736220  ...    4.000000      5.000000\n",
              "\n",
              "[23 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ldW5RJzoYvv",
        "colab_type": "text"
      },
      "source": [
        "## Use and test our MixedTabularList ItemList with the Data Block API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E2TnfwUoYvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_cols = ['business_id', 'user_id', 'business_stars', 'business_postal_code', 'business_state']\n",
        "# cont_cols = ['useful', 'user_average_stars', 'user_review_count', 'business_review_count']\n",
        "cont_cols = ['useful', 'user_average_stars', 'business_review_count']\n",
        "txt_cols = ['text']\n",
        "\n",
        "dep_var = ['stars']\n",
        "\n",
        "procs = [FillMissing, Categorify, Normalize]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK3wBZq0oYvx",
        "colab_type": "text"
      },
      "source": [
        "**Step 1: Define the source of your inputs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWGqN-84oYvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "il = MixedTabularList.from_df(joined_df, cat_cols, cont_cols, txt_cols, vocab=None, procs=procs, path=PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1tnwOVdsqu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "e4bc0847-d6c7-4b5c-f501-93562945e8e3"
      },
      "source": [
        "print(f'CATS:\\n{il.cat_names}')\n",
        "print(f'CONTS:\\n{il.cont_names}')\n",
        "print(f'TEXT COLS:\\n{il.text_cols}')\n",
        "print(f'PROCS:\\n{il.procs}')\n",
        "print('')\n",
        "print(il.get(0))"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CATS:\n",
            "['business_id', 'user_id', 'business_stars', 'business_postal_code', 'business_state']\n",
            "CONTS:\n",
            "['useful', 'user_average_stars', 'business_review_count']\n",
            "TEXT COLS:\n",
            "['text']\n",
            "PROCS:\n",
            "[<class 'fastai.tabular.transform.FillMissing'>, <class 'fastai.tabular.transform.Categorify'>, <class 'fastai.tabular.transform.Normalize'>]\n",
            "\n",
            "business_id                                         8jpIK1WHmzzbXPaK51GenQ\n",
            "user_id                                             g6gTSnUKZIxLZPQVrFKscw\n",
            "business_stars                                                         3.5\n",
            "business_postal_code                                                 85226\n",
            "business_state                                                          AZ\n",
            "useful                                                                   1\n",
            "user_average_stars                                                    4.14\n",
            "business_review_count                                                   67\n",
            "text                     I've been here at least 10 times ... I like it...\n",
            "Name: 0, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIlZ0J8GoYv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "58b997e1-e6d4-4782-b6df-f2cc1bc80b91"
      },
      "source": [
        "print(f'CATS:\\n{il.cat_names}')\n",
        "print(f'CONTS:\\n{il.cont_names}')\n",
        "print(f'TEXT COLS:\\n{il.text_cols}')\n",
        "print(f'PROCS:\\n{il.procs}')\n",
        "print('')\n",
        "print(il.get(0))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CATS:\n",
            "['business_id', 'user_id', 'business_stars', 'business_postal_code', 'business_state']\n",
            "CONTS:\n",
            "['useful', 'user_average_stars', 'business_review_count']\n",
            "TEXT COLS:\n",
            "['text']\n",
            "PROCS:\n",
            "[<class 'fastai.tabular.transform.FillMissing'>, <class 'fastai.tabular.transform.Categorify'>, <class 'fastai.tabular.transform.Normalize'>]\n",
            "\n",
            "business_id                                         8jpIK1WHmzzbXPaK51GenQ\n",
            "user_id                                             g6gTSnUKZIxLZPQVrFKscw\n",
            "business_stars                                                         3.5\n",
            "business_postal_code                                                 85226\n",
            "business_state                                                          AZ\n",
            "useful                                                                   1\n",
            "user_average_stars                                                    4.14\n",
            "business_review_count                                                   67\n",
            "text                     I've been here at least 10 times ... I like it...\n",
            "Name: 0, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f-dL3EwoYv3",
        "colab_type": "text"
      },
      "source": [
        "**Step 2: Split your dataset into training and validation `ItemList`s**\n",
        "\n",
        "This is going to trigger the `ItemList.new()` method getting called for each `ItemList` it needs to create (e.g., train, validation).  Here it will be called 2x, once to create the training dataset and then to create the validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRNPyzoWoYv4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0a57cb67-771a-4fab-a0e7-90a7ffd61372"
      },
      "source": [
        "ils = il.random_split_by_pct(valid_pct=0.1, seed=42)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/data_block.py:212: UserWarning: `random_split_by_pct` is deprecated, please use `split_by_rand_pct`.\n",
            "  warn(\"`random_split_by_pct` is deprecated, please use `split_by_rand_pct`.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUpUiqDCoYv-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ccbb0c5-a49e-4427-97e3-6539a503fe4a"
      },
      "source": [
        "len(ils.train), len(ils.valid), ils.path"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9178, 1019, PosixPath('/content/drive/My Drive/datafolder/YelpDataset'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtEaT2ewoYwE",
        "colab_type": "text"
      },
      "source": [
        "**Step 3: Add your labels (your targets or \"y\" values)**\n",
        "\n",
        "This will grab the targets (the \"y\") for each `ItemList` in your `ItemLists` object (e.g, `.train`, `.valid`) and build a `LabelList(Dataset)` for each accordingly that is then combined in and returned in a `LabelLists` object.\n",
        "\n",
        "You'll notice that the processor is created 1x but that .process is called 2x.  *Why?* So that the preprocessing defined by the training data is applied to the validation and optionally the test data later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6laKzQwww7_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dep_var=[\"stars\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxqNQduooYwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ll = ils.label_from_df(dep_var)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cbHb4_SoYwG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae52630a-702c-4aaa-e1e9-f64e6bf6c3d3"
      },
      "source": [
        "type(ll), type(ll.train), len(ll.lists)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(fastai.data_block.LabelLists, fastai.data_block.LabelList, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAEBRZvOoYwI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "d24ce803-0326-4d5e-f7cb-5caef61aed5b"
      },
      "source": [
        "ll.train"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelList (9178 items)\n",
              "x: MixedTabularList\n",
              "business_id wH4Q0y8C-lkq21yf4WWedw; user_id LAEJWZSvzsfWJ686VOaQig; business_stars 4.0; business_postal_code 85260; business_state AZ; business_review_count_na False; useful 0.1688; user_average_stars 1.5661; business_review_count -0.3965; Text: xxbos xxmaj although i had heard of xxmaj xxunk , mainly from seeing it xxunk in health conscious friends ' xxup ig posts , i had never tried it . xxmaj this location is rather new and conveniently located to me , so i gave it a try . xxmaj it 's xxup amazing ! xxmaj staff and the customer service they provide are phenomenal , and the having tried the juices ( fresh cold - pressed to order ) , smoothies & acai bowls , i 'm in love . xxmaj my 3 year old daughter even enjoyed the xxmaj pink xxmaj flamingo smoothie ( which they sell in kids size for little bellies ) . xxmaj they also sell pre - made detox and protein drinks in a small ready - to - go cooler area by the check out , although i have n't tried these yet . xxmaj and there 's a limited selection of granola & protein bars plus some kale chips in terms of snacks . \n",
              " \n",
              "  xxmaj if you 're craving a treat , treat the xxmaj acai xxmaj berry or xxup pb xxmaj bowl which is like sorbet almost and comes topped with fresh berries , banana & granola , making it a perfect breakfast or afternoon snack . xxmaj little less filling but equally delicious are the smoothies . xxmaj or get refreshed and xxunk with the juices without the hassle of cleaning your xxunk at home ( cuz anyone who juices knows it 's a pain in who - know - where ) ! xxmaj drinks and bowls run around $ 5 - 7 ish and there 's options to add protein , extra greens , or customize anything . \n",
              " \n",
              "  xxmaj for me , this place has been a great place to stop by with my daughter after preschool and / or a good way to ensure i do n't go grocery shopping at xxmaj sprouts ( same parking lot ) hungry :),business_id cRMC2eQ9CP6ivhEY8EdaGg; user_id TwilnpgwW43r9-O2AS4PDQ; business_stars 3.5; business_postal_code M4Y 2C5; business_state ON; business_review_count_na False; useful -0.0987; user_average_stars -0.7422; business_review_count -0.4287; Text: xxbos xxmaj last week i met up with a highschool friend for the first time after highschool graduation for burritos at xxmaj chino xxmaj locos : xxmaj dos xxmaj locos , the xxmaj church street venue . i 'd never been to this xxmaj mexican fast food joint before , but i heard great things about their burritos , which is the only thing they make and serve . i was glad to find a spotless and nicely lit dining area and knowledgeable and friendly burrito cooks / cashiers ( they 're the same person ) . \n",
              " \n",
              "  xxmaj their menu is rather limited , but that 's not necessarily a bad thing because what they offer is actually quite good and there 's something for everyone , particularly for me , the vegan : they have 1 vegetarian burrito with cheese and sour cream , but they also have 1 vegan burrito that is sans dairy and meat - \" the juicy vegan . \" xxmaj the vegan burrito was so good ... priced at $ 7.99 before taxes , it 's actually the most expensive burrito on their menu ! ! ! xxmaj the burrito consists of pressed tofu , eggplant , shitake mushrooms , glass noodles , guacamole , tomatoes , edamame beans , red onions , black beans , green peppers , cilantro , chipotle sauce , rustic rice ... all wrapped in a whole wheat wrap . ( xxmaj you have the option between white and whole wheat ) . xxmaj the cooks told me that they made their own guacamole at the restaurant , and to me , anything made from scratch is a big bonus ! xxmaj one set back to my burrito experience was the hot sauce ... it was n't hot enough , even though i 'd asked for extra hot xxup -i xxup love spicy food . \n",
              " \n",
              "  xxmaj you should check this place out if you like xxmaj asian food and xxmaj mexican food ... the xxmaj asian - xxmaj mexican influence on my burrito made it a crazy dining experience for my taste buds ... those xxmaj chino xxmaj locos xxunk ! ( xxmaj translation , xxmaj chino xxmaj locos = \" crazy xxmaj asians \" in xxmaj spanish ) .,business_id 1vLf-v7foAu3tJ7vAEoKdA; user_id l3okl_UjyNdqRKAzYGdWaA; business_stars 5.0; business_postal_code 85254; business_state AZ; business_review_count_na False; useful -0.3662; user_average_stars -0.9780; business_review_count -0.2821; Text: xxbos xxmaj our xxmaj bulldog xxup loves this place and so do we ! xxmaj wonderful husband and wife team that are true dog lovers . xxmaj ca n't speak highly enough of them . xxmaj only place we really trust to leave our dog . xxmaj best advertisement though is that our dog xxunk us to their door after we get out of the car ! xxup :d,business_id bWucOPNoIjd8ECdiDyVq9Q; user_id Ck3-SikwEb0U9G7RKh-O_w; business_stars 4.5; business_postal_code 85225; business_state AZ; business_review_count_na False; useful -0.3662; user_average_stars -0.7794; business_review_count 0.0021; Text: xxbos xxmaj it was n't bad xxrep 4 . but . we have been going to xxmaj yao for several years and it 's only 2 miles away from xxmaj singing xxmaj panda . xxmaj every time i find a new xxmaj chinese place , i am disappointed ... in comparison to xxmaj yao . xxmaj singing xxmaj panda was the same feeling . xxmaj plus , we spent 30 % more money for 30 % less food than we get at xxmaj yao xxup and it was n't nearly as tasty as xxmaj yao .,business_id tIvDO_1WNbb6UAifErQ-Ug; user_id cwZ64E_XT92XesWkQh85YQ; business_stars 4.0; business_postal_code M5A 3C4; business_state ON; business_review_count_na False; useful -0.3662; user_average_stars 1.3800; business_review_count -0.2744; Text: xxbos xxmaj we were at the xxmaj distillery district in xxmaj toronto . xxmaj the xxmaj balzac has one of the most interesting the decor and spaces for a coffee shop . a xxunk ceiling , funky decor and friendly staff makes for a great place to enjoy the well - made xxmaj flat xxmaj white i ordered . \n",
              " \n",
              "  i would recommend searching out xxmaj balzac xxmaj coffee shop if you 're in xxmaj toronto .\n",
              "y: CategoryList\n",
              "5,3,5,2,5\n",
              "Path: /content/drive/My Drive/datafolder/YelpDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0XZsnLpoYwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "4b7142bb-2f89-487d-d3d0-134800ad756b"
      },
      "source": [
        "ll.train.x[0], ll.train.y[0], ll.train.x.codes[0], ll.train.x.cat_names, ll.train.x.text_ids[0]"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(MixedTabularLine business_id wH4Q0y8C-lkq21yf4WWedw; user_id LAEJWZSvzsfWJ686VOaQig; business_stars 4.0; business_postal_code 85260; business_state AZ; business_review_count_na False; useful 0.1688; user_average_stars 1.5661; business_review_count -0.3965; Text: xxbos xxmaj although i had heard of xxmaj xxunk , mainly from seeing it xxunk in health conscious friends ' xxup ig posts , i had never tried it . xxmaj this location is rather new and conveniently located to me , so i gave it a try . xxmaj it 's xxup amazing ! xxmaj staff and the customer service they provide are phenomenal , and the having tried the juices ( fresh cold - pressed to order ) , smoothies & acai bowls , i 'm in love . xxmaj my 3 year old daughter even enjoyed the xxmaj pink xxmaj flamingo smoothie ( which they sell in kids size for little bellies ) . xxmaj they also sell pre - made detox and protein drinks in a small ready - to - go cooler area by the check out , although i have n't tried these yet . xxmaj and there 's a limited selection of granola & protein bars plus some kale chips in terms of snacks . \n",
              "  \n",
              "   xxmaj if you 're craving a treat , treat the xxmaj acai xxmaj berry or xxup pb xxmaj bowl which is like sorbet almost and comes topped with fresh berries , banana & granola , making it a perfect breakfast or afternoon snack . xxmaj little less filling but equally delicious are the smoothies . xxmaj or get refreshed and xxunk with the juices without the hassle of cleaning your xxunk at home ( cuz anyone who juices knows it 's a pain in who - know - where ) ! xxmaj drinks and bowls run around $ 5 - 7 ish and there 's options to add protein , extra greens , or customize anything . \n",
              "  \n",
              "   xxmaj for me , this place has been a great place to stop by with my daughter after preschool and / or a good way to ensure i do n't go grocery shopping at xxmaj sprouts ( same parking lot ) hungry :),\n",
              " Category 5,\n",
              " array([7188, 3002,    7,  308,    2,    1]),\n",
              " ['business_id',\n",
              "  'user_id',\n",
              "  'business_stars',\n",
              "  'business_postal_code',\n",
              "  'business_state',\n",
              "  'business_review_count_na'],\n",
              " array([  2,   5, 545,  13, ..., 215,  52, 779, 612]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUqoYdC7oYwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eafc859e-a6c7-40f0-9c9c-2c8a78df281b"
      },
      "source": [
        "len(ll.train.x.vocab.itos), len(ll.valid.x.vocab.itos)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15488, 15488)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMeRBPI7oYwP",
        "colab_type": "text"
      },
      "source": [
        "**Step 6: Build your DataBunch**\n",
        "\n",
        "We're skilling steps 4 (add a test dataset) and 5 (apply data augmentation) since we have neither a test set or any transforms we need to apply to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_Hj4yphoYwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "f12f9697-0420-4d27-9bec-5829a6b1d411"
      },
      "source": [
        "data_bunch = ll.databunch(bs=64)\n",
        "b = data_bunch.one_batch()\n",
        "len(b), len(b[0]), len(b[0][0]), len(b[0][1]), len(b[0][1]), b[1].shape"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-143-22c9af1a32dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_bunch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_bunch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/data_block.py\u001b[0m in \u001b[0;36mdatabunch\u001b[0;34m(self, path, bs, val_bs, num_workers, dl_tfms, device, collate_fn, no_check, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         data = self.x._bunch.create(self.train, self.valid, test_ds=self.test, path=path, bs=bs, val_bs=val_bs,\n\u001b[0;32m--> 547\u001b[0;31m                                     num_workers=num_workers, dl_tfms=dl_tfms, device=device, collate_fn=collate_fn, no_check=no_check, **kwargs)\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'normalize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#In case a normalization was serialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-128-cd1fa57ea061>\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, train_ds, valid_ds, test_ds, path, bs, pad_idx, pad_first, no_check, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         return super().create(train_ds, valid_ds, test_ds, path=path, bs=bs,\n\u001b[0;32m---> 10\u001b[0;31m                                collate_fn = collate_fn,  **kwargs) #no_check=no_check,\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: create() got multiple values for keyword argument 'collate_fn'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnSSNhoAoYwV",
        "colab_type": "text"
      },
      "source": [
        "`len(b) = 2`:  the inputs and the targets\n",
        "\n",
        "`len(b[0]) = 3`: the three things in the input (cats, conts, text_ids)\n",
        "\n",
        "`len(b[0][0|1|2|]) = 64`: there are 64 of each of the 3 things (so there is a list 64 categorical tensors followed by a list of 64 continuous tensors that is followed by a list of 64 text tensors)\n",
        "\n",
        "The shape length of the categorical and continuous tensors are the same for every batch, whereas the shape of the numericalized token ids will be the same *per* batch thanks to the `mixed_tabular_pad_collate` function above.  This fulfills the requirement that each of the inputs be a squared matrix per batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xetQ8mcoYwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b[0][0][0], b[0][1][0], b[0][2][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1wmoYf2oYwZ",
        "colab_type": "text"
      },
      "source": [
        "The above shows the categorical, continuous, and token ids for the first item in the batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uWYgC1hoYwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_bunch.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKj9Uoy-oYwc",
        "colab_type": "text"
      },
      "source": [
        "Because we included the `Normalize` proc, notice that the continuous variables are normalized *per dataset*: \n",
        "`(x - x.mean) / x.std`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4MmN_JgoYwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}